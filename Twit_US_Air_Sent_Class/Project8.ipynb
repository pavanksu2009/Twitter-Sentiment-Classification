{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuUlC4Y5kLNF"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W-bv0d3nkLNG"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWXDrhRhkLNG",
    "outputId": "cd84f716-a83a-46ea-9cad-fc5879d5d9d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\pavanksu2009\\.virtualenvs\\twit_us_air_sent_class-4caezrq-\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\pavanksu2009\\.virtualenvs\\twit_us_air_sent_class-4caezrq-\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\pavanksu2009\\.virtualenvs\\twit_us_air_sent_class-4caezrq-\\lib\\site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
      "Requirement already satisfied: anyascii in c:\\users\\pavanksu2009\\.virtualenvs\\twit_us_air_sent_class-4caezrq-\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pavanksu2009\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pavanksu2009\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re, string, unicodedata\n",
    "import contractions                                     \n",
    "from bs4 import BeautifulSoup                           \n",
    "import nltk  \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujhpLH3HkLNG"
   },
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Cj-BImx7kLNG"
   },
   "outputs": [],
   "source": [
    "# Read the file\n",
    "data=pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIjpFYhWkLNG"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idJuXTPWkLNG",
    "outputId": "306619dc-b390-4915-b894-8e4ee1f1f8ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()       # Info about dataframe, columns, data types, Null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZheLHFowkLNH",
    "outputId": "948a018c-4172-43a1-c1f0-91a51cdc56da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape of dataset\n",
    "data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "clrab5kSkLNH",
    "outputId": "2c6b037a-48e9-4ce0-968d-d2d319f4881c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first five rows of dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XmteBazxkLNH",
    "outputId": "d91fb783-af15-42f8-bbc7-d74dae62d3f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Number of Nulls-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tweet_id                            0\n",
       "airline_sentiment                   0\n",
       "airline_sentiment_confidence        0\n",
       "negativereason                   5462\n",
       "negativereason_confidence        4118\n",
       "airline                             0\n",
       "airline_sentiment_gold          14600\n",
       "name                                0\n",
       "negativereason_gold             14608\n",
       "retweet_count                       0\n",
       "text                                0\n",
       "tweet_coord                     13621\n",
       "tweet_created                       0\n",
       "tweet_location                   4733\n",
       "user_timezone                    4820\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('-----Number of Nulls-----')\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P6m_9j3pkLNH",
    "outputId": "11ee77c3-ae60-427a-dd2c-b5e2f1b990ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Number of unique values-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tweet_id                        14485\n",
       "airline_sentiment                   3\n",
       "airline_sentiment_confidence     1023\n",
       "negativereason                     10\n",
       "negativereason_confidence        1410\n",
       "airline                             6\n",
       "airline_sentiment_gold              3\n",
       "name                             7701\n",
       "negativereason_gold                13\n",
       "retweet_count                      18\n",
       "text                            14427\n",
       "tweet_coord                       832\n",
       "tweet_created                   14247\n",
       "tweet_location                   3081\n",
       "user_timezone                      85\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('-----Number of unique values-----')\n",
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "Nvh_NALRkLNH",
    "outputId": "6383b217-8432-4d0b-981b-c6796fdfb36b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.464000e+04</td>\n",
       "      <td>14640.000000</td>\n",
       "      <td>10522.000000</td>\n",
       "      <td>14640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.692184e+17</td>\n",
       "      <td>0.900169</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.082650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.791112e+14</td>\n",
       "      <td>0.162830</td>\n",
       "      <td>0.330440</td>\n",
       "      <td>0.745778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.675883e+17</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.685592e+17</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.694779e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.698905e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.703106e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id  airline_sentiment_confidence  negativereason_confidence  \\\n",
       "count  1.464000e+04                  14640.000000               10522.000000   \n",
       "mean   5.692184e+17                      0.900169                   0.638298   \n",
       "std    7.791112e+14                      0.162830                   0.330440   \n",
       "min    5.675883e+17                      0.335000                   0.000000   \n",
       "25%    5.685592e+17                      0.692300                   0.360600   \n",
       "50%    5.694779e+17                      1.000000                   0.670600   \n",
       "75%    5.698905e+17                      1.000000                   1.000000   \n",
       "max    5.703106e+17                      1.000000                   1.000000   \n",
       "\n",
       "       retweet_count  \n",
       "count   14640.000000  \n",
       "mean        0.082650  \n",
       "std         0.745778  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max        44.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLgIRowxkLNH"
   },
   "source": [
    "* As we from above there are 15 columns. \n",
    "* Some of the columns do have null values.\n",
    "* The shape of data frame is 14640 rows and 15 columns\n",
    "* Also, there are no null values for 'airline_sentiment' and 'text' column which we will use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nqibs6sakLNH"
   },
   "source": [
    "## Create a new dataset with columns 'text' and 'airline_sentiment' only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tDN7qAr7kLNH"
   },
   "outputs": [],
   "source": [
    "data_new = data[['text', 'airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GSh6lf_YkLNH",
    "outputId": "8939b1fb-b91d-4bdd-e5b3-1da89f2efeb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape of new dataset\n",
    "data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "1Bqh6ZqVkLNH",
    "outputId": "abd0530c-6380-4845-dde8-845dad6f5ec3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0                @VirginAmerica What @dhepburn said.           neutral\n",
       "1  @VirginAmerica plus you've added commercials t...          positive\n",
       "2  @VirginAmerica I didn't today... Must mean I n...           neutral\n",
       "3  @VirginAmerica it's really aggressive to blast...          negative\n",
       "4  @VirginAmerica and it's a really big bad thing...          negative"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first five rows of new dataset\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oIw856wRkLNH",
    "outputId": "791d9a29-c4f4-46ad-c8a8-52ac916f407d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the value count of airline_sentiment\n",
    "data_new.airline_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "F2AaZHNPPQH4",
    "outputId": "4a07dd79-602f-4491-ae15-c85c6bc9c900"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  airline_sentiment\n",
       "0                @VirginAmerica What @dhepburn said.                  1\n",
       "1  @VirginAmerica plus you've added commercials t...                  2\n",
       "2  @VirginAmerica I didn't today... Must mean I n...                  1\n",
       "3  @VirginAmerica it's really aggressive to blast...                  0\n",
       "4  @VirginAmerica and it's a really big bad thing...                  0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode target categorical variable (airline_sentiment)\n",
    "le = preprocessing.LabelEncoder()\n",
    "data_new.airline_sentiment = le.fit_transform(data.airline_sentiment)\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fI1OM-GDPYaI",
    "outputId": "33a72f45-2ea7-44a0-bd94-c5a63f40d8b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9178\n",
       "1    3099\n",
       "2    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.airline_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9xFDlZvvbXZ"
   },
   "source": [
    "--> \"0\" represents \"negative\" sentiments\n",
    "\n",
    "--> \"1\" represents \"neutral\" sentiments\n",
    "\n",
    "--> \"2\" represents \"positive\" sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rL6ydNKfkLNH"
   },
   "source": [
    "## Text Pre-processing and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "e85RjgoqkLNH"
   },
   "outputs": [],
   "source": [
    "## Define functions for text pre-processing\n",
    "\n",
    "## Remove HTML tags\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "## Remove contractions\n",
    "def replace_contractions(text):\n",
    "    \"\"\"Replace contractions in string of text\"\"\"\n",
    "    return contractions.fix(text)\n",
    "\n",
    "## Remove the numbers\n",
    "def remove_numbers(words):\n",
    "  new_words = []                        # Create empty list to store pre-processed words.\n",
    "  for word in words:\n",
    "    new_word = re.sub(r'\\d+', '', word)\n",
    "    if new_word != '':\n",
    "       new_words.append(new_word)    # Append processed words to new list.\n",
    "  return new_words\n",
    "\n",
    "## Remove special characters\n",
    "def remove_special_characters(words):\n",
    "  new_words = []                        # Create empty list to store pre-processed words.\n",
    "  for word in words:\n",
    "     new_word = re.sub('\\W+',' ', word)\n",
    "     if new_word != '':\n",
    "        new_words.append(new_word)    # Append processed words to new list.\n",
    "  return new_words\n",
    "\n",
    "## Remove punctuations\n",
    "def remove_punctuation(words):\n",
    "    new_words = []                        # Create empty list to store pre-processed words.\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)    # Append processed words to new list.\n",
    "    return new_words\n",
    "\n",
    "## Convert to lower case\n",
    "def to_lowercase(words):\n",
    "    new_words = []                        # Create empty list to store pre-processed words.\n",
    "    for word in words:\n",
    "        new_word = word.lower()           \n",
    "        new_words.append(new_word)        # Append processed words to new list.\n",
    "    return new_words\n",
    "\n",
    "## Lemmatize\n",
    "def lemmatize_list(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "      new_words.append(lemmatizer.lemmatize(word, pos='v'))\n",
    "    return new_words\n",
    "\n",
    "## Normalize function\n",
    "def normalize(words):\n",
    "    words = remove_numbers(words)\n",
    "    words = remove_special_characters(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = lemmatize_list(words)\n",
    "    return ' '.join(words)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "igX0HY3lyeIE",
    "outputId": "be6f4855-61a6-4722-9294-58402fce9e58"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you have added commercials...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I did not today... Must mean I ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it is really aggressive to blas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it is a really big bad thin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  airline_sentiment\n",
       "0                @VirginAmerica What @dhepburn said.                  1\n",
       "1  @VirginAmerica plus you have added commercials...                  2\n",
       "2  @VirginAmerica I did not today... Must mean I ...                  1\n",
       "3  @VirginAmerica it is really aggressive to blas...                  0\n",
       "4  @VirginAmerica and it is a really big bad thin...                  0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Apply Text preprocessing\n",
    "data_new['text'] = data_new['text'].apply(lambda x: strip_html(x))              # Remove HTML tags\n",
    "data_new['text'] = data_new['text'].apply(lambda x: replace_contractions(x))    # Replace contractions (e.g. I've, You've etc.)\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "dM5gqHCUTsUe",
    "outputId": "72999fb1-195a-4af0-babe-dffc2ba7b880"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[@, VirginAmerica, What, @, dhepburn, said, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[@, VirginAmerica, plus, you, have, added, com...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[@, VirginAmerica, I, did, not, today, ..., Mu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[@, VirginAmerica, it, is, really, aggressive,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[@, VirginAmerica, and, it, is, a, really, big...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  airline_sentiment\n",
       "0     [@, VirginAmerica, What, @, dhepburn, said, .]                  1\n",
       "1  [@, VirginAmerica, plus, you, have, added, com...                  2\n",
       "2  [@, VirginAmerica, I, did, not, today, ..., Mu...                  1\n",
       "3  [@, VirginAmerica, it, is, really, aggressive,...                  0\n",
       "4  [@, VirginAmerica, and, it, is, a, really, big...                  0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenization \n",
    "data_new['text'] = data_new.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "_cNKYRZ775Iu",
    "outputId": "d3ad3429-1952-48ca-f307-2943eda89365"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virginamerica what   dhepburn say</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virginamerica plus you have add commercials ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>virginamerica i do not today   must mean i n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virginamerica it be really aggressive to bla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica and it be a really big bad thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  airline_sentiment\n",
       "0                virginamerica what   dhepburn say                    1\n",
       "1    virginamerica plus you have add commercials ...                  2\n",
       "2    virginamerica i do not today   must mean i n...                  1\n",
       "3    virginamerica it be really aggressive to bla...                  0\n",
       "4    virginamerica and it be a really big bad thi...                  0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Normalize the data and join the words back to the text string\n",
    "data_new['text'] = data_new.apply(lambda row: normalize(row['text']), axis=1)\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFwbPYeWmoHk"
   },
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gk1O-c9gYmnH",
    "outputId": "b6ae3cf6-a709-440b-f040-110a887d8d5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Count vectorizer\n",
    "vectorizer = CountVectorizer(max_features=1000)                # Keep only 1000 features as number of features will increase the processing time.\n",
    "data_count = vectorizer.fit_transform(data_new['text'])\n",
    "\n",
    "data_count = data_count.toarray()                        # Convert the data features to array.\n",
    "data_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqqyTSVJgbIS",
    "outputId": "7adf4278-6f7b-47e8-b4f8-fc81b344cdec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TFIDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "data_tfidf = vectorizer.fit_transform(data_new['text'])\n",
    "\n",
    "data_tfidf = data_tfidf.toarray()                        # Convert the data features to array.\n",
    "data_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1Lk8u4MrKvm"
   },
   "source": [
    "## Use Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EB0IxMgWoV6U"
   },
   "outputs": [],
   "source": [
    "# Get target column\n",
    "labels = data_new['airline_sentiment']\n",
    "\n",
    "# Split data into training and testing set for Count Vector\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_count, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAYMMWpUrRnV",
    "outputId": "48280e58-12b3-4311-c076-8e3ebe1b43bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=10, n_jobs=4)\n",
      "0.71974043715847\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10, n_jobs=4)\n",
    "forest = forest.fit(x_train, y_train)\n",
    "print(forest)\n",
    "\n",
    "print(np.mean(cross_val_score(forest, data_count, labels, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CIkoC7CTsSmG",
    "outputId": "2c8276b4-3631-40ac-81e7-0c6fa2efef0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2607  145   62]\n",
      " [ 449  381   54]\n",
      " [ 219  110  365]]\n"
     ]
    }
   ],
   "source": [
    "# Predict the result\n",
    "result = forest.predict(x_test)\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, result)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "sKr2UPjTsteq"
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing set for TFIDF Vector\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_tfidf, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sye_Yn7wstdd",
    "outputId": "ed8ea34f-9466-4595-8f42-0065014d18ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=10, n_jobs=4)\n",
      "0.7172131147540984\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10, n_jobs=4)\n",
    "forest = forest.fit(x_train, y_train)\n",
    "print(forest)\n",
    "\n",
    "print(np.mean(cross_val_score(forest, data_count, labels, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['challa_forest.sav']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "joblib.dump(forest, 'challa_forest.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7518214936247724"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = joblib.load('challa_forest.sav')\n",
    "loaded_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsyejlGqtsbH",
    "outputId": "f0db90e9-1f68-4766-a177-512df8b6fe24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2642  120   52]\n",
      " [ 480  339   65]\n",
      " [ 279   94  321]]\n"
     ]
    }
   ],
   "source": [
    "# Predict the result\n",
    "result = forest.predict(x_test)\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, result)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMPHFQ3exJZA"
   },
   "source": [
    "## Summary\n",
    "\n",
    "* We used the text of the tweet and the sentiment represented by the tweet which could be either positive, negative or neutral.\n",
    "* The objective was to build a classification model.\n",
    "* The text pre-processing was done by removing HTML tags, replacing contractions, removing numbers, special characters and punctuations. We also converted text to lower case and used lemmatization for tokenized words.\n",
    "* This pre-processed data was then converted to numbers using vectorization techniques; count vectorization and TFIDF vectorization to be used for random forest classifier.\n",
    "* The random forest classifier was used for predicting the results.\n",
    "* For count vectorization technique, we got a cross validation score of 71.7% whereas for TFIDF vectorization, we got 72% 10 fold cross validation score.\n",
    "* The performance of the model can be increased by using different classification models or neural networks besides changing the number of features for vectorization and also by using other pre-processing techniques like removing stop words etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Twit_US_Air_Sent_Class-4CaEZrq-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "328e7932fa71edf082a87215e16523be2345f74378b3a444abb596505ec61080"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
